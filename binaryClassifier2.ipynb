{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jakebaldwin/Documents/binaryC-GRU-predictions/binaryClassifier2.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakebaldwin/Documents/binaryC-GRU-predictions/binaryClassifier2.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakebaldwin/Documents/binaryC-GRU-predictions/binaryClassifier2.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         testData\u001b[39m.\u001b[39mappend(fileName)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jakebaldwin/Documents/binaryC-GRU-predictions/binaryClassifier2.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(trainData[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakebaldwin/Documents/binaryC-GRU-predictions/binaryClassifier2.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39miloc[\u001b[39m3\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "files = ['./data/' + f for f in listdir('./data/') if isfile(join('./data/', f))]\n",
    "\n",
    "trainData = []\n",
    "valData = []\n",
    "testData = []\n",
    "\n",
    "for i, fileName in enumerate(files):\n",
    "    if i < 1:\n",
    "        trainData.append(fileName)\n",
    "    elif i > 120 and i < 160:\n",
    "        valData.append(fileName)\n",
    "    else:\n",
    "        testData.append(fileName)\n",
    "\n",
    "\n",
    "df = pd.read_csv(trainData[1])\n",
    "\n",
    "print(df.iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, files, transform=None, target=None):\n",
    "        self.lengths = []\n",
    "        self.data = []\n",
    "\n",
    "        for f in files:\n",
    "            df = pd.read_csv(f)\n",
    "            df = df.dropna()\n",
    "            df = df[df.OneHotPred != 'X']\n",
    "            df = df[df.OneHotPred != 'UP']\n",
    "            df = df[df.OneHotPred != 'DOWN']\n",
    "            df = df.reset_index(drop=True)\n",
    "            #df = df[df[5] != 'UP']\n",
    "            self.lengths.append(len(df) - 2)\n",
    "            self.data.append(df)\n",
    "\n",
    "        self.transforms = transform\n",
    "        self.target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.lengths) - 5\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        i = 0\n",
    "        while idx > self.lengths[i]:\n",
    "            idx -= self.lengths[i]\n",
    "            i += 1\n",
    "        \n",
    "        rowsBack = 5\n",
    "        quiz = torch.zeros(5)\n",
    "        label = torch.zeros(1)\n",
    "        quizI = 0\n",
    "\n",
    "        while rowsBack > 0:\n",
    "\n",
    "            if i < 0:\n",
    "                i -= 1\n",
    "                idx = self.lengths[i]\n",
    "            \n",
    "            row = self.data[i].iloc[idx - rowsBack]\n",
    "            if row[1] == 'UP' or row[1] == 'DOWN':\n",
    "                quiz[quizI] = torch.tensor(float(24))\n",
    "            else:\n",
    "                quiz[quizI] = torch.tensor(float(row[1]))\n",
    "                \n",
    "            quizI += 1\n",
    "\n",
    "            if rowsBack == 5:\n",
    "                try:\n",
    "                    label = torch.tensor(int(row[7]))\n",
    "                except:\n",
    "                    label = torch.tensor(int(1))\n",
    "\n",
    "            rowsBack -= 1\n",
    "\n",
    "        quiz = quiz.div(quiz.norm())\n",
    "\n",
    "        return quiz, label\n",
    "        \n",
    "\n",
    "trainDataset = CustomImageDataset(trainData)\n",
    "valDataset = CustomImageDataset(valData)\n",
    "testDataset = CustomImageDataset(testData)\n",
    "        \n",
    "train_dataloader = DataLoader(trainDataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(valDataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(testDataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_shape, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 16)\n",
    "        self.apool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.sigmoid(self.apool(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, 128) #fully connected 1\n",
    "        self.fc = nn.Linear(128, num_classes) #fully connected last layer\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, self.hidden_size)) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out) #first Dense\n",
    "        out = self.relu(out) #relu\n",
    "        out = self.fc(out) #Final Output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\tloss : 0.6817439198493958\t accuracy : 0.4959958217270195\n",
      "epoch 10\tloss : 0.6885291337966919\t accuracy : 0.5067896935933147\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jakebaldwin/Documents/binaryC-GRU-predictions/binaryClassifier2.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakebaldwin/Documents/binaryC-GRU-predictions/binaryClassifier2.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m#acc = (output.reshape(-1,1).detach().numpy().round() == y_train)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakebaldwin/Documents/binaryC-GRU-predictions/binaryClassifier2.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m#backprop\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakebaldwin/Documents/binaryC-GRU-predictions/binaryClassifier2.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jakebaldwin/Documents/binaryC-GRU-predictions/binaryClassifier2.ipynb#W3sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakebaldwin/Documents/binaryC-GRU-predictions/binaryClassifier2.ipynb#W3sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakebaldwin/Documents/binaryC-GRU-predictions/binaryClassifier2.ipynb#W3sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mif\u001b[39;00m i\u001b[39m%\u001b[39m\u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "learning_rate = 0.01\n",
    "epochs = 500\n",
    "\n",
    "model = LSTM1(num_classes=1, input_size=torch.rand(5).shape[0], hidden_size=16,num_layers=16,seq_length=16)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "losses = []\n",
    "accur = []\n",
    "for i in range(epochs):\n",
    "  accs = []\n",
    "  for j,(x_train,y_train) in enumerate(train_dataloader):\n",
    "    \n",
    "    if y_train.size() == torch.Size([16]):\n",
    "      #calculate output\n",
    "\n",
    "      output = model(x_train)\n",
    "      #output = torch.FloatTensor(output.squeeze())\n",
    "      y_train = y_train.type(torch.FloatTensor)\n",
    "      output = output.squeeze().type(torch.FloatTensor)\n",
    "      #calculate loss\n",
    "\n",
    "      loss = loss_fn(output, y_train)\n",
    "\n",
    "      #print(output)\n",
    "      #accuracy\n",
    "      accL = [int(round(o.item()) == i.item()) for o, i in zip(output.reshape(-1,1), y_train)]\n",
    "      accs.append(sum(accL)/len(accL))\n",
    "      #acc = (output.reshape(-1,1).detach().numpy().round() == y_train)\n",
    "      #backprop\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "  if i%10 == 0:\n",
    "    losses.append(loss)\n",
    "    acc = sum(accs) / len(accs)\n",
    "    accur.append(acc)\n",
    "    print(\"epoch {}\\tloss : {}\\t accuracy : {}\".format(i,loss,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.0000e+02, 4.9007e-01, 9.7844e-01, 5.4038e-01, 5.2689e-01, 7.4568e-01,\n",
      "        5.9110e-02, 4.1122e-01, 8.1013e-01, 2.3858e-02, 5.1585e-01, 3.7455e-01,\n",
      "        3.5590e-01, 3.8111e-01, 8.1493e-02, 6.6522e-01, 2.2686e-01, 1.0374e-01,\n",
      "        9.0794e-01, 5.9440e-01, 2.4592e-02, 4.7589e-01, 5.2140e-01, 7.7238e-01,\n",
      "        8.8578e-01])\n",
      "torch.Size([25])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([9.9996e-01, 1.6335e-03, 3.2613e-03, 1.8012e-03, 1.7562e-03, 2.4855e-03,\n",
       "        1.9703e-04, 1.3707e-03, 2.7003e-03, 7.9522e-05, 1.7194e-03, 1.2485e-03,\n",
       "        1.1863e-03, 1.2703e-03, 2.7163e-04, 2.2173e-03, 7.5618e-04, 3.4577e-04,\n",
       "        3.0264e-03, 1.9812e-03, 8.1969e-05, 1.5862e-03, 1.7379e-03, 2.5745e-03,\n",
       "        2.9525e-03])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "k = torch.rand(25)\n",
    "k[0] = torch.tensor(300)\n",
    "print(k)\n",
    "print(k.shape)\n",
    "k.div(k.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>A US Equity</th>\n",
       "      <th>A US Equity.1</th>\n",
       "      <th>A US Equity.2</th>\n",
       "      <th>A US Equity.3</th>\n",
       "      <th>A US Equity.4</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>OneHotPred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2000-08-31</td>\n",
       "      <td>41.1</td>\n",
       "      <td>41.5211</td>\n",
       "      <td>40.7631</td>\n",
       "      <td>39.0728</td>\n",
       "      <td>50.0361</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2000-09-01</td>\n",
       "      <td>41.6896</td>\n",
       "      <td>40.8895</td>\n",
       "      <td>41.2179</td>\n",
       "      <td>38.8858</td>\n",
       "      <td>50.1435</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2000-09-05</td>\n",
       "      <td>41.6475</td>\n",
       "      <td>41.5632</td>\n",
       "      <td>41.6475</td>\n",
       "      <td>38.7064</td>\n",
       "      <td>50.2035</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>40.4262</td>\n",
       "      <td>41.5632</td>\n",
       "      <td>41.2432</td>\n",
       "      <td>38.5026</td>\n",
       "      <td>50.2696</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2000-09-07</td>\n",
       "      <td>41.6922</td>\n",
       "      <td>40.4262</td>\n",
       "      <td>41.3111</td>\n",
       "      <td>38.3199</td>\n",
       "      <td>50.3298</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5762</th>\n",
       "      <td>2022-11-22</td>\n",
       "      <td>156.86</td>\n",
       "      <td>151.98</td>\n",
       "      <td>147.95</td>\n",
       "      <td>133.5466</td>\n",
       "      <td>129.2391</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5763</th>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>155.35</td>\n",
       "      <td>156.67</td>\n",
       "      <td>149.596</td>\n",
       "      <td>133.9886</td>\n",
       "      <td>129.3118</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5764</th>\n",
       "      <td>2022-11-25</td>\n",
       "      <td>156.96</td>\n",
       "      <td>155.09</td>\n",
       "      <td>152.1</td>\n",
       "      <td>134.4646</td>\n",
       "      <td>129.3744</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5765</th>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>152.3</td>\n",
       "      <td>155.87</td>\n",
       "      <td>153.322</td>\n",
       "      <td>134.9128</td>\n",
       "      <td>129.4276</td>\n",
       "      <td>DOWN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5766</th>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>150.94</td>\n",
       "      <td>151.88</td>\n",
       "      <td>154.482</td>\n",
       "      <td>135.3172</td>\n",
       "      <td>129.4963</td>\n",
       "      <td>UP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5597 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ticker A US Equity A US Equity.1 A US Equity.2 A US Equity.3  \\\n",
       "170   2000-08-31        41.1       41.5211       40.7631       39.0728   \n",
       "171   2000-09-01     41.6896       40.8895       41.2179       38.8858   \n",
       "172   2000-09-05     41.6475       41.5632       41.6475       38.7064   \n",
       "173   2000-09-06     40.4262       41.5632       41.2432       38.5026   \n",
       "174   2000-09-07     41.6922       40.4262       41.3111       38.3199   \n",
       "...          ...         ...           ...           ...           ...   \n",
       "5762  2022-11-22      156.86        151.98        147.95      133.5466   \n",
       "5763  2022-11-23      155.35        156.67       149.596      133.9886   \n",
       "5764  2022-11-25      156.96        155.09         152.1      134.4646   \n",
       "5765  2022-11-28       152.3        155.87       153.322      134.9128   \n",
       "5766  2022-11-29      150.94        151.88       154.482      135.3172   \n",
       "\n",
       "     A US Equity.4 Predictions OneHotPred  \n",
       "170        50.0361          UP          1  \n",
       "171        50.1435        DOWN          0  \n",
       "172        50.2035        DOWN          0  \n",
       "173        50.2696          UP          1  \n",
       "174        50.3298        DOWN          0  \n",
       "...            ...         ...        ...  \n",
       "5762      129.2391        DOWN          0  \n",
       "5763      129.3118          UP          1  \n",
       "5764      129.3744        DOWN          0  \n",
       "5765      129.4276        DOWN          0  \n",
       "5766      129.4963          UP          1  \n",
       "\n",
       "[5597 rows x 8 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/A.csv')\n",
    "df = df.dropna()\n",
    "df = df[df.OneHotPred != 'X']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 5",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/jakebaldwin/Documents/binaryC-GRU-predictions/binaryClassifier.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jakebaldwin/Documents/binaryC-GRU-predictions/binaryClassifier.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m5\u001b[39;49m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 5"
     ]
    }
   ],
   "source": [
    "df[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
